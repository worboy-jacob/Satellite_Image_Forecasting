{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom Dataset Loader to merge images with vegetation layer\n",
    "class PovertyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset for satellite images with 4 channels: RGB + vegetation.\n",
    "    images_filenames: List of file paths to images (each has 4 channels).\n",
    "    targets: List or array of poverty values (floats).\n",
    "    transform: Optional set of transforms (e.g., scaling, augmentations).\n",
    "    \"\"\"\n",
    "    def __init__(self, images_filenames, targets, transform=None):\n",
    "        self.images_filenames = images_filenames\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images_filenames[idx]\n",
    "        with Image.open(img_path) as img:\n",
    "            # Convert to 4 channels, e.g., \"RGBA\" if your file includes a 4th band\n",
    "            # If the vegetation channel is separate, you'd have to load it separately \n",
    "            # and stack them. This example assumes your file already has 4 channels.\n",
    "            img = img.convert(\"RGBA\")\n",
    "            img_np = np.array(img, dtype=np.float32)\n",
    "\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            img_np = self.transform(img_np)\n",
    "\n",
    "        return img_np, np.float32(target)\n",
    "\n",
    "\n",
    "# Define Transforms\n",
    "class ToTensor:\n",
    "    \"\"\"Convert a numpy array (H, W, C) to a PyTorch tensor of shape (C, H, W).\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        sample_tensor = torch.from_numpy(sample).permute(2, 0, 1)  # (C,H,W)\n",
    "        return sample_tensor\n",
    "\n",
    "class MinMaxScale:\n",
    "    \"\"\"\n",
    "    Scale each pixel channel-wise from [min_val, max_val] to [0,1].\n",
    "    Adjust min_val/max_val to match your data's range.\n",
    "    \"\"\"\n",
    "    def __init__(self, min_val=0.0, max_val=255.0):\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "\n",
    "    def __call__(self, sample_tensor):\n",
    "        return (sample_tensor - self.min_val) / (self.max_val - self.min_val + 1e-8)\n",
    "\n",
    "\n",
    "# Compose transforms\n",
    "transform = T.Compose([\n",
    "    ToTensor(),           \n",
    "    MinMaxScale(0, 255),  \n",
    "])\n",
    "\n",
    "\n",
    "# Train/Test Split + Dataloaders\n",
    "images_filenames = [\n",
    "    # \"path/to/image1.png\",\n",
    "    # \"path/to/image2.png\",\n",
    "    # ...\n",
    "]\n",
    "targets = [\n",
    "    # poverty_value1,\n",
    "    # poverty_value2,\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# Split data\n",
    "train_files, test_files, train_targets, test_targets = train_test_split(\n",
    "    images_filenames, targets, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create Datasets\n",
    "train_dataset = PovertyDataset(train_files, train_targets, transform=transform)\n",
    "test_dataset  = PovertyDataset(test_files,  test_targets,  transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=8, shuffle=False)\n",
    "\n",
    "\n",
    "# Definition of NN\n",
    "# ResNet with a MLP regression Head\n",
    "class ResNetRegressor(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super().__init__()\n",
    "        # Load a pretrained ResNet (e.g., ResNet18)\n",
    "        self.backbone = models.resnet18(pretrained=pretrained)\n",
    "        \n",
    "        # Modify the first conv layer to accept 4 channels instead of 3\n",
    "        old_weights = self.backbone.conv1.weight.data\n",
    "        new_conv = nn.Conv2d(\n",
    "            in_channels=4, out_channels=64,\n",
    "            kernel_size=7, stride=2, padding=3, bias=False\n",
    "        )\n",
    "        # Copy the original RGB weights\n",
    "        new_conv.weight.data[:, :3, :, :] = old_weights\n",
    "        # Initialize the 4th channel\n",
    "        nn.init.xavier_normal_(new_conv.weight.data[:, 3:, :, :])\n",
    "        self.backbone.conv1 = new_conv\n",
    "\n",
    "        # Remove the original FC (classifier) and replace with Identity\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # A small MLP to map the 512-dim features to a single scalar\n",
    "        # (ResNet18 typically ends with a 512-dim feature after global pooling)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, 1)  # single output for regression\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract features via the CNN backbone\n",
    "        features = self.backbone(x)  # shape [batch_size, 512]\n",
    "        # Pass features through the MLP\n",
    "        out = self.mlp(features)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResNetRegressor(pretrained=True)\n",
    "model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 5\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # ---- TRAIN ----\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    for images, targets in train_loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device).view(-1, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_train_loss = running_train_loss / len(train_loader.dataset)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "\n",
    "    # ---- EVAL ----\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device).view(-1, 1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_test_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_test_loss = running_test_loss / len(test_loader.dataset)\n",
    "    test_losses.append(epoch_test_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {epoch_train_loss:.4f} | Test Loss: {epoch_test_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, num_epochs + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, num_epochs + 1), test_losses, label='Test Loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.title(\"Training vs. Test Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
